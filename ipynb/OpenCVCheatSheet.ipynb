{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f155db2",
   "metadata": {},
   "source": [
    "# OpenCV Cheat Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60413f51",
   "metadata": {},
   "source": [
    "### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('image', img)\n",
    "cv.waitKey(0)  # 0=indefinitely, otherwise delay in ms\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5695d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.namedWindow('window')\n",
    "cv.setMouseCallback('Image mouse', mouse_callback, param=None)\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv.EVENT_LBUTTONDOWN | cv.EVENT_LBUTTONUP |cv.EVENT_LBUTTONDBLCLK |\n",
    "                cv.EVENT_MOUSEMOVE | cv.EVENT_MOUSEWHEEL:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2f97c",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img_OpenCV[:, :, 0]\n",
    "g = img_OpenCV[:, :, 1]\n",
    "r = img_OpenCV[:, :, 2]\n",
    "# --- or ---\n",
    "b, g, r = cv.split(img)\n",
    "\n",
    "img = cv.merge((r, g, b))\n",
    "\n",
    "img_rgb = img_bgr[:, :, ::-1]\n",
    "# --- or ---\n",
    "img_rgb = cv.cvtColor(img_bgr, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44673f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gry = cv.cvtColor(img_bgr, cv.COLOR_BGR2GRAY)\n",
    "img_col = cv.applyColorMap(img_gry, cv.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa626dc",
   "metadata": {},
   "source": [
    "### Image Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_b = img[0, 0, 0]\n",
    "pix_bgr = img[0, 0]\n",
    "img_b = img[:, :, 0]\n",
    "img_slice = img[0:10, 0:20]\n",
    "\n",
    "img.fill(128)\n",
    "img[:] = 128\n",
    "img[:, :, 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack horizontally\n",
    "img_lr = np.concatenate((img_l, img_r), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea4441",
   "metadata": {},
   "source": [
    "### File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('img.png')\n",
    "img = cv.imread('img.png', cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fed9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imwrite('img.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ee879",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv.VideoCapture(0)  # 0=index_camera, also video filename\n",
    "assert capture.isOpened()\n",
    "\n",
    "width = capture.get(cv.CAP_PROP_FRAME_WIDTH)\n",
    "height = capture.get(cv.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = capture.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    if not ret: break\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795aefa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv.VideoWriter_fourcc(*'AVC1')\n",
    "# https://gist.github.com/takuma7/44f9ecb028ff00e2132e\n",
    "writer = cv.VideoWriter(video_path, fourcc, fps, width, height, is_color)\n",
    "writer.write(frame)\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d27634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigating video files\n",
    "num_frames = capture.get(cv.CAP_PROP_FRAME_COUNT)\n",
    "capture.set(cv.CAP_PROP_POS_FRAMES, <FRAME_INDEX>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd0355",
   "metadata": {},
   "source": [
    "### Drawing Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eafad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1, pt2 = (0, 0), (100, 100)\n",
    "pts = np.array([[250, 5], [220, 80], [280, 80]], np.int32).reshape((-1, 1, 2))\n",
    "color = (255, 255, 255)\n",
    "lineType = cv.LINE_4 | cv.LINE_8 | cv.LINE_AA\n",
    "thicknes = -1  # fill shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.line(img, pt1, pt2, color, thickness=1, lineType=8, shift=0)\n",
    "cv.arrowedLine(img, pt1, pt2, color, thickness=1, lineType=8, shift=0, tipLength=0.1) # pt1==>pt2\n",
    "cv.rectangle(img, pt1, pt2, color, thickness=1, lineType=8, shift=0)\n",
    "cv.circle(img, center, radius, color, thickness=1, lineType=8, shift=0)\n",
    "cv.ellipse(img, center, axes, angle, startAngle, endAngle, color,\n",
    "           thickness=1, lineType=8, shift=0)\n",
    "cv.polylines(img, pts, is_closed, color, thickness=1, lineType=8, shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = (0, 0, 50, 50)\n",
    "is_intersecting, pt1, pt2 = clipLine(rect, pt1, pt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d843a32",
   "metadata": {},
   "source": [
    "### Drawing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_face = cv.FONT_HERSHEY_SIMPLEX or cv.FONT_HERSHEY_DUPLEX or ...\n",
    "cv.putText(img, text, org, fontFace, fontScale, color,\n",
    "           thickness=1, lineType=8, bottomLeftOrigin=False)  # !bottomLeftOrigin => upperLeftOrigin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac28434",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_scale = cv.getFontScaleFromHeight(fontFace, pixelHeight, thickness=1)\n",
    "(width, height), baseLine = cv.getTextSize(text, fontFace, fontScale, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9493c6e",
   "metadata": {},
   "source": [
    "### Geometric Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing\n",
    "interpolation = cv.INTER_NEAREST | cv.INTER_LINEAR | cv.INTER_CUBIC |\n",
    "                cv.INTER_AREA | cv.INTER_LANCZOS4\n",
    "image = cv.resize(img, (width, height), interpolation=cv.INTER_LINEAR)\n",
    "image = cv.resize(img, None, fx=0.5, fy=0.5)  # dSize=None => auto-calc\n",
    "# ---\n",
    "image = cv.pyrDown(src[, dst[, dSize[, borderType]]])  # Blur and downsample (2X)\n",
    "image = cv.pyrUp(src[, dst[, dSize[, borderType]]])    # Upsample (2X) and blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aee5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation\n",
    "M = np.float32([[1, 0, translate_x],\n",
    "                [0, 1, translate_y]])\n",
    "image = cv.warpAffine(img, M, (outputWidth, outputHeight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "M = cv.getRotationMatrix2D((centerX, centerY), angleDeg, scaleFactor)\n",
    "image = cv.warpAffine(img, M, (outputWidth, outputHeight))\n",
    "# ---\n",
    "image = cv.transpose(img)  ## Rotate 90-deg CCW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82118fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transformation\n",
    "pts_1 = np.float32([[0,0], [0,1], [1,0]])\n",
    "pts_2 = np.float32([[1,1], [1,3], [4,1]])\n",
    "M = cv.getAffineTransform(pts_1, pts_2)\n",
    "image = cv.warpAffine(img, M, (outputWidth, outputHeight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transformation\n",
    "pts_1 = np.float32([[0,0], [0,1], [1,0], [1,1]])\n",
    "pts_1 = np.float32([[0,0], [0,2], [2,0], [3,3]])\n",
    "M = cv.getPerspectiveTransform(pts_1, pts_2)\n",
    "image = cv.warpPerspective(img, M, (300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd304a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horz/Vert Flipping\n",
    "# flipCode: 0 => Horz, 1 => Vert, -1 => Both\n",
    "image = cv.flip(img, flipCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5126b",
   "metadata": {},
   "source": [
    "### Image Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041006e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "# ddepth=-1 => output will have same depth as source\n",
    "image = cv.filter2D(img, ddepth, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de6530",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><table><caption>\n",
    "        \n",
    "__Sharpening Kernels__\n",
    "        \n",
    "</caption>\n",
    "<tr><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| 0  | -1 |  0 |\n",
    "| -1 |  4 | -1 |\n",
    "| 0  | -1 |  0 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| -1 | -1 | -1 |\n",
    "| -1 |  8 | -1 |\n",
    "| -1 | -1 | -1 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  1 |  1 |  1 |\n",
    "|  1 | -8 |  1 |\n",
    "|  1 |  1 |  1 |\n",
    "\n",
    "</td></tr></table></td>\n",
    "<td><table><caption>\n",
    "        \n",
    "__Sobel Kernels__\n",
    "        \n",
    "</caption>\n",
    "<tr><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| -1 |  0 |  1 |\n",
    "| -2 |  0 |  2 |\n",
    "| -1 |  0 |  1 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| -1 | -2 |  1 |\n",
    "|  0 |  0 |  0 |\n",
    "| -1 | -2 |  1 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  1 |  1 |  1 |\n",
    "|  1 | -8 |  1 |\n",
    "|  1 |  1 |  1 |\n",
    "\n",
    "</td></tr></table></td>\n",
    "<td><table><caption>\n",
    "        \n",
    "__Laplacian Kernels__\n",
    "        \n",
    "</caption>\n",
    "<tr><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  0 |  1 |  0 |\n",
    "|  1 | -4 |  1 |\n",
    "|  0 |  1 |  0 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  1 |  4 |  1 |\n",
    "|  4 |-20 |  4 |\n",
    "|  1 |  4 |  1 |\n",
    "\n",
    "</td></tr></table></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel\n",
    "# dx, dy: order of derivative\n",
    "# cv.Sobel(src, ddepth, dx, dy[, dst[, ksize=3[, ...]]])\n",
    "image_x = cv.Sobel(img, cv.CV_32F, 0, 1, ksize=5)\n",
    "image_y = cv.Sobel(img, cv.CV_32F, 1, 0, ksize=5)\n",
    "# Laplacian\n",
    "# cv.Laplacian(src, ddepth[, dst[, ksize[, ...]]])\n",
    "image = cv.Laplacian(img, cv.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8882f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsharp Mask\n",
    "smoothed = cv.GaussianBlur(img, ksize, sigmaX)\n",
    "# cv.addWeighted(src1, alpha, src2, beta, gamma)\n",
    "# dst = ðšœðš›ðšŒðŸ·âˆ—ðšŠðš•ðš™ðš‘ðšŠ + ðšœðš›ðšŒðŸ¸âˆ—ðš‹ðšŽðšðšŠ + ðšðšŠðš–ðš–ðšŠ\n",
    "unsharped = cv.addWeighted(img, 1.5, smoothed, -0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ef9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ksize = (width, height)\n",
    "# Box Blur\n",
    "image = cv.blur(img, ksize)\n",
    "# Gausssian Blur\n",
    "# sigmaX=0 => computed from ksize.width and ksize.height\n",
    "image = cv.GaussianBlur(img, ksize, sigmaX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b12097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Blur\n",
    "ksize1 = 5  # width == height\n",
    "image = cv.medianBlur(img, ksize1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef183237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilateral Blur\n",
    "# dia<0 => computed from sigmaSpatial\n",
    "image = cv.bilateralFilter(img, dia, sigmaColor, SigmaSpatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge\n",
    "image = cv.Canny(img, loThreshold1, hiThreshold, sobelApertSize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d6b4d",
   "metadata": {},
   "source": [
    "### NLM Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80253413",
   "metadata": {},
   "source": [
    "- cv.fastNlMeansDenoising() - single grayscale image\n",
    "- cv.fastNlMeansDenoisingColored() - color image\n",
    "- cv.fastNlMeansDenoisingMulti() - sequence of grayscale images\n",
    "- cv.fastNlMeansDenoisingColoredMulti() - sequence of color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3891cda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fastNlMeansDenoising(img[, dst[, h=3.0[, hColor=3.0[, templateWindowSize=7[, searchWindowSize=21]]]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15454dba",
   "metadata": {},
   "source": [
    "### Arithmetic Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66219a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturation Arithmetic\n",
    "# src1, src2: array or scalar\n",
    "image = cv.add(src1, src2)\n",
    "image = cv.subtract(src1, src2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending\n",
    "image = cv.addWeighted(src1, alpha, src2, beta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitwise\n",
    "image = cv.bitwise_not(img)\n",
    "image = cv.bitwise_and(src1, src2)\n",
    "image = cv.bitwise_or(src1, src2)\n",
    "image = cv.bitwise_xor(src1, src2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowerb: inclusive lower-bound array/scalar\n",
    "# upperb: inclusive upper-bound array/scalar\n",
    "mask = cv.inRange(img, lowerb, upperb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b9a17",
   "metadata": {},
   "source": [
    "### Morphological Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03218e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape =  cv.MORPH_RECT | cv.MORPH_ELLIPSE | cv.MORPH_CROSS\n",
    "cv.getStructuringElement(shape, ksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f98b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.dilate(img, kernel, iterations=1)\n",
    "image = cv.erode(img, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.morphologyEx(img, cv.MORPH_OPEN, kernel)      # erosion â†’ dilation\n",
    "image = cv.morphologyEx(img, cv.MORPH_CLOSE, kernel)     # dilation â†’ erosion\n",
    "image = cv.morphologyEx(img, cv.MORPH_GRADIENT, kernel)  # dilation - erosion\n",
    "image = cv.morphologyEx(img, cv.MORPH_TOPHAT, kernel)    # original - opening\n",
    "image = cv.morphologyEx(img, cv.MORPH_BLACKHAT, kernel)  # closing - original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ede7f5",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7f0c1",
   "metadata": {},
   "source": [
    "NOTE: cv.calcHist() is much faster than np.histogram() and plt.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed96c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images: list of images\n",
    "# channels: list of channel idxs, e.g. grayscale: [0], color: [0, 1, 2]\n",
    "# mask : None => no mask\n",
    "# histSize: list of # hist bins\n",
    "# ranges: range of intensity to measure (upper non-inclusive), e.g. [0, 256]\n",
    "hist = cv.calcHist([image], [channels], mask, [histSize], [ranges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "mask = np.zeros((100, 100), np.uint8)\n",
    "mask[10:90, 10:90] = 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9936ba",
   "metadata": {},
   "source": [
    "### Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale\n",
    "image = cv.equalizeHist(img_gry)\n",
    "\n",
    "# Color\n",
    "H, S, V = cv.split(cv.cvtColor(img, cv.COLOR_BGR2HSV))\n",
    "V_eq = cv.equalizeHist(V)\n",
    "image = cv.cvtColor(cv.merge([H, S, eq_V]), cv.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE\n",
    "# cv.createCLAHE(clipLimit, tileGridSize=(8,8))\n",
    "clahe = cv.createCLAHE(clipLimit=2.0)\n",
    "image = clahe.apply(img_gry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3114f",
   "metadata": {},
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe286df",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshType = (cv.THRESH_BINARY | cv.THRESH_BINARY_INV | cv.THRESH_TRUNC) + cv.THRESH_OTSU\n",
    "retval, image = cv.threshold(img, thresh, maxval, threshType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50325410",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptMethod = cv.ADAPTIVE_THRESH_MEAN_C | cv.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "# ADAPTIVE_THRESH_GAUSSIAN_C => cross-correlation with Gaussian window (sigma depends on blockSize)\n",
    "# blocksize: int\n",
    "# threshOffs: constant subtracted from the (weighted) mean\n",
    "image = adaptiveThreshold(img, maxValue, adaptMethod, threshType, blockSize, threshOffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f5dd2",
   "metadata": {},
   "source": [
    "### Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58996960",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_edge = cv.Canny(img, 30, 200)\n",
    "# mode: cv.RETR_EXTERNAL => Outer only, cv.RETR_LIST => All, cv.RETR_TREE => All /w Hierarchy\n",
    "method = cv.CHAIN_APPROX_NONE | cv.CHAIN_APPROX_SIMPLE | cv.CHAIN_APPROX_TC89_L1 | cv.CHAIN_APPROX_TC89_KCOS\n",
    "contours, hierarchy = cv.findContours(img_edge, mode, method)\n",
    "# contourIdx: -1 => all \n",
    "cv.drawContours(img, contours, contourIdx, color, thickness, lineType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955be900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour Length\n",
    "closed = True  # whether contour is closed\n",
    "epsilon = 0.03 * cv.arcLength(contour, closed)\n",
    "\n",
    "# Vertices Reduction (Polygon Approximation)\n",
    "# epsilon: max dist between original contour and its approximation\n",
    "approx = cv.approxPolyDP(contour, epsilon, closed)\n",
    "\n",
    "# Convex Hull\n",
    "hull = cv.convexHull(contour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour Area\n",
    "area = cv.contourArea(contour)\n",
    "\n",
    "# Contour Moments\n",
    "mo = cv.moments(contours)\n",
    "cx = int(mo['m10'] / mo['m00'])\n",
    "cy = int(mo['m01'] / mo['m00'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0b2d8",
   "metadata": {},
   "source": [
    "### Line / Circle Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6f476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho: Dist resolution of accumulator (px)\n",
    "# theta: Angle resolution of accumulator (rads)\n",
    "# threshold: Accummmulator (votes) threshold\n",
    "# [min_theta], [max_theta]: min/max angle to check for lines\n",
    "lines = cv.HoughLines(img_edge, rho, theta, threshold)\n",
    "\n",
    "# minLineLength: shorter line segments will be rejected\n",
    "# maxLineGap: max allowed gap between points to be on the same line \n",
    "lines = cv.HoughLinesP(img_edge, rho, theta, threshold[, lines[, minLineLength[, maxLineGap]]])\n",
    "\n",
    "# dp: image_resolution / accum_resolution\n",
    "# minDist: min dist between circle centers\n",
    "method = cv.HOUGH_GRADIENT | cv.HOUGH_GRADIENT_ALT\n",
    "circles = cv.HoughCircles(img_gry, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59327fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
