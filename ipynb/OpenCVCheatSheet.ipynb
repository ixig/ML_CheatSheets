{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f155db2",
   "metadata": {},
   "source": [
    "# OpenCV Cheat Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d8356",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60413f51",
   "metadata": {},
   "source": [
    "### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(0)  # 0=indefinitely, otherwise delay in ms\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5695d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('window')\n",
    "cv2.setMouseCallback('Image mouse', mouse_callback, param=None)\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN | cv2.EVENT_LBUTTONUP |cv2.EVENT_LBUTTONDBLCLK |\n",
    "                cv2.EVENT_MOUSEMOVE | cv2.EVENT_MOUSEWHEEL:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d2f97c",
   "metadata": {},
   "source": [
    "### Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831fd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = img_OpenCV[:, :, 0]\n",
    "g = img_OpenCV[:, :, 1]\n",
    "r = img_OpenCV[:, :, 2]\n",
    "# --- or ---\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "img = = cv2.merge((r, g, b))\n",
    "\n",
    "img_rgb = img_bgr[:, :, ::-1]\n",
    "# --- or ---\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44673f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gry = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "img_col = cv2.applyColorMap(img_gry, cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa626dc",
   "metadata": {},
   "source": [
    "### Image Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5880fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_b = img[0, 0, 0]\n",
    "pix_bgr = img[0, 0]\n",
    "img_b = img[:, :, 0]\n",
    "img_slice = img[0:10, 0:20]\n",
    "\n",
    "img[:] = 128  # img.fill(128)\n",
    "img[:, :, 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack horizontally\n",
    "img_lr = np.concatenate((img_l, img_r), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea4441",
   "metadata": {},
   "source": [
    "### File I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee3e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('img.png')\n",
    "img = cv2.imread('img.png', cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fed9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('img.jpg', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ee879",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)  # 0=index_camera, also video filename\n",
    "assert capture.isOpened()\n",
    "\n",
    "width = capture.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    if not ret: break\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795aefa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'AVC1')\n",
    "# https://gist.github.com/takuma7/44f9ecb028ff00e2132e\n",
    "writer = cv2.VideoWriter(video_path, fourcc, fps, width, height, is_color)\n",
    "writer.write(frame)\n",
    "writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d27634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigating video files\n",
    "num_frames = capture.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "capture.set(cv2.CAP_PROP_POS_FRAMES, <FRAME_INDEX>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd0355",
   "metadata": {},
   "source": [
    "### Drawing Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eafad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt1, pt2 = (0, 0), (100, 100)\n",
    "pts = np.array([[250, 5], [220, 80], [280, 80]], np.int32).reshape((-1, 1, 2))\n",
    "color = (255, 255, 255)\n",
    "lineType = cv2.LINE_4 | cv2.LINE_8 | cv2.LINE_AA\n",
    "thicknes = -1  # fill shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e6c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.line(img, pt1, pt2, color, thickness=1, lineType=8, shift=0)\n",
    "cv.arrowedLine(img, pt1, pt2, color, thickness=1, lineType=8, shift=0, tipLength=0.1) # pt1=>pt2\n",
    "cv2.rectangle(img, pt1, pt2, color, thickness=1, lineType=8, shift=0)\n",
    "cv2.circle(img, center, radius, color, thickness=1, lineType=8, shift=0)\n",
    "cv2.ellipse(img, center, axes, angle, startAngle, endAngle, color,\n",
    "            thickness=1, lineType=8, shift=0)\n",
    "cv2.polylines(img, pts, is_closed, color, thickness=1, lineType=8, shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee1d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = (0, 0, 50, 50)\n",
    "is_intersecting, pt1, pt2 = clipLine(rect, pt1, pt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d843a32",
   "metadata": {},
   "source": [
    "### Drawing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_face = cv2.FONT_HERSHEY_SIMPLEX or cv.FONT_HERSHEY_DUPLEX or ...\n",
    "cv.putText(img, text, org, fontFace, fontScale, color,\n",
    "           thickness=1, lineType=8, bottomLeftOrigin=False)  # !bottomLeftOrigin => upperLeftOrigin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac28434",
   "metadata": {},
   "outputs": [],
   "source": [
    "font_scale = cv2.getFontScaleFromHeight(fontFace, pixelHeight, thickness=1)\n",
    "(width, height), baseLine = cv2.getTextSize(text, fontFace, fontScale, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9493c6e",
   "metadata": {},
   "source": [
    "### Geometric Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013d9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation = cv2.INTER_NEAREST | cv2.INTER_LINEAR | cv2.INTER_CUBIC |\n",
    "                cv2.INTER_AREA | cv2.INTER_LANCZOS4\n",
    "resized_img = cv2.resize(img, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "resized_img = cv2.resize(img, None, fx=0.5, fy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aee5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation\n",
    "M = np.float32([[1, 0, translate_x],\n",
    "                [0, 1, translate_y]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd87285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "M = cv2.getRotationMatrix2D(center_height, center_width), angleDeg, scaleFactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82118fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_1 = np.float32([[0,0], [0,1], [1,0]])\n",
    "pts_2 = np.float32([[1,1], [1,3], [4,1]])\n",
    "M = cv2.getAffineTransform(pts_1, pts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90777d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine Transformation\n",
    "image = cv2.warpAffine(img, M, (output_height, output_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perspective Transformaion\n",
    "pts_1 = np.float32([[0,0], [0,1], [1,0], [1,1]])\n",
    "pts_1 = np.float32([[0,0], [0,2], [2,0], [3,3]])\n",
    "M = cv2.getPerspectiveTransform(pts_1, pts_2)\n",
    "image = cv2.warpPerspective(img, M, (300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5126b",
   "metadata": {},
   "source": [
    "### Image Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041006e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "# ddepth=-1 => output will have same depth as source\n",
    "image = cv2.filter2D(img, ddepth, kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de6530",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td><table><caption>\n",
    "        \n",
    "__Sharpening Kernels__\n",
    "        \n",
    "</caption>\n",
    "<tr><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| 0  | -1 |  0 |\n",
    "| -1 |  4 | -1 |\n",
    "| 0  | -1 |  0 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| -1 | -1 | -1 |\n",
    "| -1 |  8 | -1 |\n",
    "| -1 | -1 | -1 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  1 |  1 |  1 |\n",
    "|  1 | -8 |  1 |\n",
    "|  1 |  1 |  1 |\n",
    "\n",
    "</td></tr></table></td>\n",
    "<td><table><caption>\n",
    "        \n",
    "__Sobel Kernels__\n",
    "        \n",
    "</caption>\n",
    "<tr><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| -1 |  0 |  1 |\n",
    "| -2 |  0 |  2 |\n",
    "| -1 |  0 |  1 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "| -1 | -2 |  1 |\n",
    "|  0 |  0 |  0 |\n",
    "| -1 | -2 |  1 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  1 |  1 |  1 |\n",
    "|  1 | -8 |  1 |\n",
    "|  1 |  1 |  1 |\n",
    "\n",
    "</td></tr></table></td>\n",
    "<td><table><caption>\n",
    "        \n",
    "__Laplacian Kernels__\n",
    "        \n",
    "</caption>\n",
    "<tr><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  0 |  1 |  0 |\n",
    "|  1 | -4 |  1 |\n",
    "|  0 |  1 |  0 |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "|    |    |    |\n",
    "|----|----|----|\n",
    "|  1 |  4 |  1 |\n",
    "|  4 |-20 |  4 |\n",
    "|  1 |  4 |  1 |\n",
    "\n",
    "</td></tr></table></td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8882f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsharp Mask\n",
    "smoothed = cv2.GaussianBlur(img, ksize, sigmaX)\n",
    "# cv2.addWeighted(src1, alpha, src2, beta, gamma)\n",
    "# dst = 𝚜𝚛𝚌𝟷∗𝚊𝚕𝚙𝚑𝚊 + 𝚜𝚛𝚌𝟸∗𝚋𝚎𝚝𝚊 + 𝚐𝚊𝚖𝚖𝚊\n",
    "unsharped = cv2.addWeighted(img, 1.5, smoothed, -0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ef9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gausssian Blur\n",
    "ksize = (width, height)\n",
    "# sigmaX=0 => computed from ksize.width and ksize.height\n",
    "image = cv2.GaussianBlur(img, ksize, sigmaX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b12097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Blur\n",
    "ksize1 = 5  # width == height\n",
    "image = cv2.medianBlur(img, ksize1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef183237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilateral Blur\n",
    "# dia<0 => computed from sigmaSpatial\n",
    "image = cv2.bilateralFilter(img, dia, sigmaColor, SigmaSpatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge\n",
    "image = cv.Canny(img, loThreshold1, hiThreshold, sobelApertSize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15454dba",
   "metadata": {},
   "source": [
    "### Arithmetic Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66219a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturation Arithmetic\n",
    "# src1, src2: array or scalar\n",
    "image = cv2.add(src1, src2)\n",
    "image = cv2.subtract(src1, src2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blending\n",
    "image = cv2.addWeighted(src1, alpha, src2, beta, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bitwise\n",
    "image = cv2.bitwise_not(img)\n",
    "image = cv2.bitwise_and(src1, src2)\n",
    "image = cv2.bitwise_or(src1, src2)\n",
    "image = cv2.bitwise_xor(src1, src2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95bb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowerb: inclusive lower-bound array/scalar\n",
    "# upperb: inclusive upper-bound array/scalar\n",
    "mask = cv2.inRange(img, lowerb, upperb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b9a17",
   "metadata": {},
   "source": [
    "### Morphological Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03218e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape =  cv.MORPH_RECT | cv.MORPH_ELLIPSE | cv.MORPH_CROSS\n",
    "cv2.getStructuringElement(shape, ksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f98b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.dilate(img, kernel, iterations=1)\n",
    "image = cv2.erode(img, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)      # erosion → dilation\n",
    "image = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)     # dilation → erosion\n",
    "image = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)  # dilation - erosion\n",
    "image = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)    # original - opening\n",
    "image = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)  # closing - original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ede7f5",
   "metadata": {},
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7f0c1",
   "metadata": {},
   "source": [
    "NOTE: cv2.calcHist() is much faster than np.histogram() and plt.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed96c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images: list of images\n",
    "# channels: list of channel idxs, e.g. grayscale: [0], color: [0, 1, 2]\n",
    "# mask : None => no mask\n",
    "# histSize: list of # bins\n",
    "# ranges: range of intensity to measure, e.g. [0, 256]\n",
    "\n",
    "# cv2.calcHist([image], [channel], mask, [histSize], [range])\n",
    "hist = cv2.calcHist([img_bgr], [0], None, [256], [0, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masks\n",
    "mask = np.zeros((100, 100), np.uint8)\n",
    "mask[10:90, 10:90] = 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9936ba",
   "metadata": {},
   "source": [
    "### Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b7c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale\n",
    "image = cv2.equalizeHist(img_gry)\n",
    "\n",
    "# Color\n",
    "H, S, V = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2HSV))\n",
    "V_eq = cv2.equalizeHist(V)\n",
    "image = cv2.cvtColor(cv2.merge([H, S, eq_V]), cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE\n",
    "# cv2.createCLAHE(clipLimit, tileGridSize=(8,8))\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0)\n",
    "image = clahe.apply(img_gry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3114f",
   "metadata": {},
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe286df",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshType = cv2.THRESH_BINARY | cv2.THRESH_BINARY_INV | cv2.THRESH_TRUNC | cv2.THRESH_OTSU\n",
    "retval, image = cv2.threshold(img, thresh, maxval, threshType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50325410",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptMethod = cv2.ADAPTIVE_THRESH_MEAN_C | cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "# ADAPTIVE_THRESH_GAUSSIAN_C => cross-correlation with Gaussian window (sigma depends on blockSize)\n",
    "# blocksize: int\n",
    "# threshOffs: constant subtracted from the (weighted) mean\n",
    "image = adaptiveThreshold(img, maxValue, adaptMethod, threshType, blockSize, threshOffs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
